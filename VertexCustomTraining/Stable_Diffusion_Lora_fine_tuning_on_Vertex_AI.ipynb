{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "alXRFyMWz7tP"
      },
      "source": [
        "# **Notebook - Stable Diffusion Lora fine tuning on Vertex AI**\n",
        "\n",
        "This notebook copies all codes and scripts here, just for a view. You can also directly use the code file."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Architecture:**\n",
        "- **train.py** : model training file in Docker\n",
        "- **Dockerfile**\n",
        "- **cloud-build-config.yaml** : cloud config file used in CLI\n",
        "- **vertex-ai-config.yaml** : : cloud config file used in CLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY8UaaUqxAdy"
      },
      "outputs": [],
      "source": [
        "%%writefile train.py\n",
        "import subprocess\n",
        "import os\n",
        "import argparse\n",
        "import re\n",
        "import torch\n",
        "from safetensors.torch import save_file\n",
        "\n",
        "def bin_to_safetensors(output_path):\n",
        "    newDict = dict();\n",
        "    checkpoint = torch.load(output_path + '/pytorch_lora_weights.bin');\n",
        "    for idx, key in enumerate(checkpoint):\n",
        "      newKey = re.sub('\\.processor\\.', '_', key);\n",
        "      newKey = re.sub('mid_block\\.', 'mid_block_', newKey);\n",
        "      newKey = re.sub('_lora.up.', '.lora_up.', newKey);\n",
        "      newKey = re.sub('_lora.down.', '.lora_down.', newKey);\n",
        "      newKey = re.sub('\\.(\\d+)\\.', '_\\\\1_', newKey);\n",
        "      newKey = re.sub('to_out', 'to_out_0', newKey);\n",
        "      newKey = 'lora_unet_'+newKey;\n",
        "\n",
        "      newDict[newKey] = checkpoint[key];\n",
        "\n",
        "    newLoraName = 'pytorch_lora_weights.safetensors';\n",
        "    print(\"Saving \" + newLoraName);\n",
        "    save_file(newDict, output_path + '/' + newLoraName);\n",
        "\n",
        "def main(args):\n",
        "\n",
        "    MODEL_NAME= args.model_name #\"runwayml/stable-diffusion-v1-5\"\n",
        "    INSTANCE_DIR= args.input_storage\n",
        "    OUTPUT_DIR= args.output_storage\n",
        "    PROMPT = args.prompt\n",
        "\n",
        "    os.chdir(\"/root/diffusers/examples/dreambooth\")\n",
        "\n",
        "    # for complex commands, with many args, use string + `shell=True`:\n",
        "    cmd_str = (f'accelerate launch train_dreambooth_lora.py '\n",
        "               f'--pretrained_model_name_or_path=\"{MODEL_NAME}\" '\n",
        "               f'--instance_data_dir=\"{INSTANCE_DIR}\" '\n",
        "               f'--output_dir=\"{OUTPUT_DIR}\" '\n",
        "               f'--instance_prompt=\"{PROMPT}\" '\n",
        "               f' --resolution=512 '\n",
        "               f'--train_batch_size=1 '\n",
        "               f'--use_8bit_adam '\n",
        "               f'--mixed_precision=\"fp16\" '\n",
        "               f'--gradient_accumulation_steps=1 '\n",
        "               f'--learning_rate=1e-4 '\n",
        "               f'--lr_scheduler=\"constant\" '\n",
        "               f'--lr_warmup_steps=0 '\n",
        "               f'--max_train_steps=400')\n",
        "\n",
        "    subprocess.run(cmd_str, shell=True)\n",
        "    # Convert .bin file to .safetensors, to be used in Automatic111 WebUI\n",
        "    bin_to_safetensors(args.output_storage)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--model_name\", type=str, default=\"runwayml/stable-diffusion-v1-5\", help=\"bucket_name/model_folder\")\n",
        "    parser.add_argument(\"--input_storage\", type=str,default=\"abc\", help=\"/gcs/bucket_name/input_image_folder\")\n",
        "    parser.add_argument(\"--output_storage\", type=str, default=\"abc\",help=\"/gcs/bucket_name/output_folder\")\n",
        "    parser.add_argument(\"--prompt\", type=str, default=\"abc\",help=\"a photo of XXX\")\n",
        "    \n",
        "    args = parser.parse_args()\n",
        "    print(args.model_name)\n",
        "    print(args.input_storage)\n",
        "    print(args.output_storage)\n",
        "    print(args.prompt)\n",
        "    main(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3w5dWRYbRQ-L"
      },
      "outputs": [],
      "source": [
        "%%writefile Dockerfile\n",
        "FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04\n",
        "\n",
        "RUN apt update\n",
        "RUN apt install -y wget git python3 python3-venv python3-pip\n",
        "\n",
        "RUN pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "WORKDIR /root\n",
        "\n",
        "RUN git clone -b v0.14.0 https://github.com/huggingface/diffusers.git \\\n",
        "  && pip install /root/diffusers \\\n",
        "  && pip install -U -r /root/diffusers/examples/dreambooth/requirements.txt \\\n",
        "  && pip install -U -r /root/diffusers/examples/text_to_image/requirements.txt \\\n",
        "  && pip install -U xformers \\ \n",
        "  && pip install -U safetensors\n",
        "\n",
        "# Solve Bitbytes and CUDA conflict issue\n",
        "ENV LD_LIBRARY_PATH $LD_LIBRARY_PATH:/usr/local/cuda/lib64\n",
        "RUN ln -s /usr/local/cuda/lib64/libcudart.so.11.0 /usr/local/cuda/lib64/libcudart.so\n",
        "RUN pip install -U bitsandbytes --prefer-binary\n",
        "\n",
        "# Config accelerate\n",
        "RUN accelerate config default --mixed_precision=fp16\n",
        "\n",
        "# Installs additional packages as you need.\n",
        "RUN pip install google-cloud-aiplatform\n",
        "RUN pip install google-cloud-storage\n",
        "\n",
        "# Copies the trainer code to the docker image.\n",
        "COPY train.py /root/train.py\n",
        "\n",
        "# Sets up the entry point to invoke the trainer.\n",
        "ENTRYPOINT [\"python3\", \"-m\", \"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSDuYpoZF8m-"
      },
      "outputs": [],
      "source": [
        "#cloud build config: modify docker image name and tag\n",
        "%%writefile cloud-build-config.yaml\n",
        "steps:\n",
        "- name: 'gcr.io/cloud-builders/docker'\n",
        "  args: [ 'build', '-t', 'us-central1-docker.pkg.dev/project_id/artifact_registry_name/sd-training:db-lora-v1', '.' ]\n",
        "- name: 'gcr.io/cloud-builders/docker'\n",
        "  args: ['push', 'us-central1-docker.pkg.dev/project_id/artifact_registry_name/sd-training:db-lora-v1']\n",
        "options:\n",
        "  machineType: 'N1_HIGHCPU_8'\n",
        "  diskSizeGb: '200'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sn6qxXsM1Jc9"
      },
      "outputs": [],
      "source": [
        "#vertex ai config: modify docker image name and tag\n",
        "%%writefile vertex-ai-config.yaml\n",
        "workerPoolSpecs:\n",
        "  machineSpec:\n",
        "    machineType: n1-standard-8\n",
        "    acceleratorType: NVIDIA_TESLA_T4\n",
        "    acceleratorCount: 1\n",
        "  replicaCount: 1\n",
        "  containerSpec:\n",
        "    imageUri: us-central1-docker.pkg.dev/project_id/artifact_registry_id/sd-training:db-lora-v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTIy8wBa1pNA"
      },
      "outputs": [],
      "source": [
        "# cloud build image\n",
        "! gcloud builds submit --config cloud-build-config.yaml .\n",
        "\n",
        "# create vertex ai customer training job\n",
        "# args format:\n",
        "# --model_name: Huggingface repo id, or \"/gcs/bucket_name/model_folder\". I only test the models downloaded from HF, with standard diffusers format. Safetensors has not been test.\n",
        "# --input_storage:/gcs/bucket_name/input_image_folder\n",
        "# --output_storage: /gcs/bucket_name/output_folder\n",
        "# --prompt: a photo of XXX\n",
        "! gcloud ai custom-jobs create \\\n",
        "  --region=us-central1 \\\n",
        "  --display-name=sd-lora-training-args-0314-noyh \\\n",
        "  --config=vertex-ai-config.yaml \\\n",
        "  --args=\"--model_name=runwayml/stable-diffusion-v1-5,--input_storage=/gcs/sd_lsj/input_dog,--output_storage=/gcs/sd_lsj/dog_lora_output,--prompt=a photo of sks dog\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS5cqSia1kte"
      },
      "source": [
        "When training finished, you can load the base model and lora weights for inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgpdZ_Nv1MF_"
      },
      "outputs": [],
      "source": [
        "# inference with fine-tuned lora model\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "model_path = \"/somewhere/dog_lora_output\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
        "pipe.unet.load_attn_procs(model_path)\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"A sks dog in the desert.\"\n",
        "image = pipe(prompt, num_inference_steps=30, guidance_scale=7.5).images[0]\n",
        "image.save(\"dog_lora.png\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "m5pyZ_kv8m3O"
      },
      "source": [
        "Convert .bin file to safetensors, to use in Automatic1111 WebUI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tr788sXw8mVA"
      },
      "outputs": [],
      "source": [
        "import os;\n",
        "import re;\n",
        "import torch;\n",
        "from safetensors.torch import save_file;\n",
        "\n",
        "newDict = dict();\n",
        "checkpoint = torch.load('dog_lora_output/pytorch_lora_weights.bin');\n",
        "for idx, key in enumerate(checkpoint):\n",
        "    newKey = re.sub('\\.processor\\.', '_', key);\n",
        "    newKey = re.sub('mid_block\\.', 'mid_block_', newKey);\n",
        "    newKey = re.sub('_lora.up.', '.lora_up.', newKey);\n",
        "    newKey = re.sub('_lora.down.', '.lora_down.', newKey);\n",
        "    newKey = re.sub('\\.(\\d+)\\.', '_\\\\1_', newKey);\n",
        "    newKey = re.sub('to_out', 'to_out_0', newKey);\n",
        "    newKey = 'lora_unet_'+newKey;\n",
        "\n",
        "    newDict[newKey] = checkpoint[key];\n",
        "\n",
        "newLoraName = 'pytorch_lora_weights.safetensors';\n",
        "print(\"Saving \" + newLoraName);\n",
        "save_file(newDict, newLoraName);"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "h5dnViBHzOZ-"
      },
      "source": [
        "Alternatives: Dowload and save Stable Diffusion model from Huggingface to GCS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UWVslWVHmbk"
      },
      "outputs": [],
      "source": [
        "! pip install diffusers\n",
        "! pip install transformers\n",
        "! pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2qzuAQ0HsJs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "pipeline = DiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    revision=\"fp16\",\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "pipeline.save_pretrained(\"model_weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJYwWU9S0zqv"
      },
      "outputs": [],
      "source": [
        "! gsutil cp -r model_weights gs://bucket_name/folder"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
